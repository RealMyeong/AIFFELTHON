{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68128f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntensorflow = 2.8.0\\nkeras = 2.6.0\\ntransformers = 4.11.3\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tensorflow = 2.8.0\n",
    "keras = 2.6.0\n",
    "transformers = 4.11.3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee5ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4442b1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 29 04:50:27 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    39W / 300W |      0MiB / 16384MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714b5502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/wlsaud5474/aiffelthon/notebook', '/home/wlsaud5474/anaconda3/envs/jinmyeong/lib/python37.zip', '/home/wlsaud5474/anaconda3/envs/jinmyeong/lib/python3.7', '/home/wlsaud5474/anaconda3/envs/jinmyeong/lib/python3.7/lib-dynload', '', '/home/wlsaud5474/anaconda3/envs/jinmyeong/lib/python3.7/site-packages', '/home/wlsaud5474/anaconda3/envs/jinmyeong/lib/python3.7/site-packages/IPython/extensions', '/home/wlsaud5474/.ipython', '/home/wlsaud5474/aiffelthon']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getenv('HOME')+'/aiffelthon')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10395b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bert import modeling_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9401f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import re\n",
    "import pyarrow as pa\n",
    "from datasets import Dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f03dd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>non_label_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>길동 씨 이번에 이것 좀 처리해요\\n이거 제가 한 게 아닌데요\\n팀에서 내가 네가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>야 너 앞니 왜 그렇게 튀어나왔냐\\n태어날 때부터 그랬어 물어보지 마\\n아 그럼 태...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>원후야 학원 교재 사야 되는데 8만 원만 주면 안 돼\\n미안 나 오늘은 진짜 돈이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>너 저번에 술 먹은 날 기억해\\n아니 왜\\n야 300만 원만 가져와\\n뭔 소리야  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>너 또 내말 무시하냐\\n이 새끼 널 좆으로 보나 본데\\n아냐 진짜 시간이 없었어 미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26970</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>혹시 자기소개서 써봤어\\n한번도 안 써봤어\\n자기소개서 쓰는 것 정말 힘들어\\n너는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26971</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>나 이번에 화상으로 수업 듣다가 졸았잖아 키키\\n키키 인강 안 듣다가 왠일로 들었어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26972</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>비행기 타 본 적 있어\\n나 고등학교 졸업여행 때 한 번\\n오 졸업여행도 갔었나\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26973</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>너는 학생 때 어떤 쌤이 제일 좋았어\\n나는   별로 좋았던 쌤이 없었어\\n중학생 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26974</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>도와 드릴까요\\n관련해서 문의 좀 할게요\\n네 어떤 문의로 연락주셨나요\\n제가 제품...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             class                                 non_label_sentence\n",
       "0      직장 내 괴롭힘 대화  길동 씨 이번에 이것 좀 처리해요\\n이거 제가 한 게 아닌데요\\n팀에서 내가 네가 ...\n",
       "1        기타 괴롭힘 대화  야 너 앞니 왜 그렇게 튀어나왔냐\\n태어날 때부터 그랬어 물어보지 마\\n아 그럼 태...\n",
       "2            갈취 대화  원후야 학원 교재 사야 되는데 8만 원만 주면 안 돼\\n미안 나 오늘은 진짜 돈이 ...\n",
       "3            갈취 대화  너 저번에 술 먹은 날 기억해\\n아니 왜\\n야 300만 원만 가져와\\n뭔 소리야  ...\n",
       "4            협박 대화  너 또 내말 무시하냐\\n이 새끼 널 좆으로 보나 본데\\n아냐 진짜 시간이 없었어 미...\n",
       "...            ...                                                ...\n",
       "26970        일반 대화  혹시 자기소개서 써봤어\\n한번도 안 써봤어\\n자기소개서 쓰는 것 정말 힘들어\\n너는...\n",
       "26971        일반 대화  나 이번에 화상으로 수업 듣다가 졸았잖아 키키\\n키키 인강 안 듣다가 왠일로 들었어...\n",
       "26972        일반 대화  비행기 타 본 적 있어\\n나 고등학교 졸업여행 때 한 번\\n오 졸업여행도 갔었나\\n...\n",
       "26973        일반 대화  너는 학생 때 어떤 쌤이 제일 좋았어\\n나는   별로 좋았던 쌤이 없었어\\n중학생 ...\n",
       "26974        일반 대화  도와 드릴까요\\n관련해서 문의 좀 할게요\\n네 어떤 문의로 연락주셨나요\\n제가 제품...\n",
       "\n",
       "[26975 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data_dir = os.getenv('HOME')+'/aiffelthon/AIFFELTHON/TUNiB/experiment_data'\n",
    "data = pd.read_csv(f\"{data_dir}/train_bt_en_fr_ch_8000.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54642008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(['label_sentence', 'binary_class'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3697c06c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>non_label_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>길동 씨 이번에 이것 좀 처리해요\\n이거 제가 한 게 아닌데요\\n팀에서 내가 네가 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>야 너 앞니 왜 그렇게 튀어나왔냐\\n태어날 때부터 그랬어 물어보지 마\\n아 그럼 태...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>원후야 학원 교재 사야 되는데 8만 원만 주면 안 돼\\n미안 나 오늘은 진짜 돈이 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>너 저번에 술 먹은 날 기억해\\n아니 왜\\n야 300만 원만 가져와\\n뭔 소리야  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>너 또 내말 무시하냐\\n이 새끼 널 좆으로 보나 본데\\n아냐 진짜 시간이 없었어 미...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>야 돼지 오늘도 돈 내놔\\n오늘은 진짜 없어\\n아새끼 오늘 진짜 돈 안 들고 왔네\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>오 신발 샀냐\\n응  전에 신던 게 다 헤져서  부모님이 사주셨어\\n너네 집 꽤 사...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>영하 학생 이리 나와요\\n네 선생님\\n선생님이 왜 부른 줄 알아\\n잘 모르겠습니다 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>씨 오늘 뭐 해요\\n아 저 약속이 있어서요\\n누구랑요  남자친구\\n아  네\\n에이 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>야 죽기 싫으면 돈 내놔\\n죄송합니다  여기\\n뭔 이거 밖 없어  뒤져서 나오면 죽...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class                                 non_label_sentence  label\n",
       "0  직장 내 괴롭힘 대화  길동 씨 이번에 이것 좀 처리해요\\n이거 제가 한 게 아닌데요\\n팀에서 내가 네가 ...      2\n",
       "1    기타 괴롭힘 대화  야 너 앞니 왜 그렇게 튀어나왔냐\\n태어날 때부터 그랬어 물어보지 마\\n아 그럼 태...      3\n",
       "2        갈취 대화  원후야 학원 교재 사야 되는데 8만 원만 주면 안 돼\\n미안 나 오늘은 진짜 돈이 ...      1\n",
       "3        갈취 대화  너 저번에 술 먹은 날 기억해\\n아니 왜\\n야 300만 원만 가져와\\n뭔 소리야  ...      1\n",
       "4        협박 대화  너 또 내말 무시하냐\\n이 새끼 널 좆으로 보나 본데\\n아냐 진짜 시간이 없었어 미...      0\n",
       "5        갈취 대화  야 돼지 오늘도 돈 내놔\\n오늘은 진짜 없어\\n아새끼 오늘 진짜 돈 안 들고 왔네\\...      1\n",
       "6    기타 괴롭힘 대화  오 신발 샀냐\\n응  전에 신던 게 다 헤져서  부모님이 사주셨어\\n너네 집 꽤 사...      3\n",
       "7    기타 괴롭힘 대화  영하 학생 이리 나와요\\n네 선생님\\n선생님이 왜 부른 줄 알아\\n잘 모르겠습니다 ...      3\n",
       "8  직장 내 괴롭힘 대화  씨 오늘 뭐 해요\\n아 저 약속이 있어서요\\n누구랑요  남자친구\\n아  네\\n에이 ...      2\n",
       "9        갈취 대화  야 죽기 싫으면 돈 내놔\\n죄송합니다  여기\\n뭔 이거 밖 없어  뒤져서 나오면 죽...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels = {'협박 대화':0, '갈취 대화':1, '직장 내 괴롭힘 대화':2, '기타 괴롭힘 대화':3, '일반 대화':4}\n",
    "num_labels = len(labels)\n",
    "data['label'] = data['class'].apply(lambda x : labels[x])\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a714c5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from transformers import ElectraForSequenceClassification, RobertaForSequenceClassification\n",
    "from bert.modeling_bert import BertForSequenceClassification \n",
    "\n",
    "HUGGINGFACE_MODEL_PATH = \"klue/bert-base\"\n",
    "# \"klue/roberta-large\"\n",
    "# \"beomi/kcbert-large\"\n",
    "# \"beomi/KcELECTRA-base-v2022\"\n",
    "# \"klue/bert-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(HUGGINGFACE_MODEL_PATH)\n",
    "#model = AutoModel.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "model = BertForSequenceClassification.from_pretrained(HUGGINGFACE_MODEL_PATH, num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c9155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(pa.Table.from_pandas(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a58e6df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869aaffc4d9949f08ae3dc7c613e821c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform(data):\n",
    "  return tokenizer(\n",
    "      data['non_label_sentence'],\n",
    "      truncation = True,\n",
    "      padding = 'max_length',\n",
    "      return_token_type_ids = True,\n",
    "      )\n",
    "\n",
    "encoded_data = data.map(transform, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3de8316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset= encoded_data.train_test_split(test_size=0.1).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1213ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['class', 'non_label_sentence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 24277\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10b48d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wlsaud5474/anaconda3/envs/jinmyeong/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):    \n",
    "    predictions,labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references = labels, average=\"micro\")\n",
    "\n",
    "output_dir = os.getenv('HOME')+'/aiffelthon/AIFFELTHON/Fine_tuning/KcBERT-large'\n",
    "\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir, \n",
    "    evaluation_strategy=\"epoch\", #evaluation하는 빈도\n",
    "    learning_rate = 2e-5, \n",
    "    per_device_train_batch_size = 8, \n",
    "    per_device_eval_batch_size = 8, \n",
    "    num_train_epochs = 2,\n",
    "    weight_decay = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f5a8de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: class, non_label_sentence. If class, non_label_sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/wlsaud5474/anaconda3/envs/jinmyeong/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 24277\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6070\n",
      "  Number of trainable parameters = 110621189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='6070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  34/6070 00:08 < 25:26, 3.95 it/s, Epoch 0.01/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3711/1814470528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/jinmyeong/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         )\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jinmyeong/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1747\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m                 if (\n",
      "\u001b[0;32m~/anaconda3/envs/jinmyeong/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2526\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jinmyeong/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jinmyeong/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                           \n",
    "    args=training_arguments,                  \n",
    "    train_dataset=train_dataset,    \n",
    "    eval_dataset=validation_dataset,      \n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d901c4",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = os.getenv('HOME')+'/aiffelthon/AIFFELTHON/TUNiB/test.json'\n",
    "with open(test_file_path, mode='rt', encoding='utf-8') as f:\n",
    "    test_dataset = pd.read_json(f)\n",
    "\n",
    "test_data = test_dataset.transpose()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def remove_punctuation(x):\n",
    "  x = x.strip()\n",
    "  x = re.sub(\"[^가-힣0-9]+\", \" \", x)\n",
    "  x = re.sub(\"[ ]+\", \" \", x)\n",
    "  x = x.strip()\n",
    "  return x\n",
    "\n",
    "test_data[\"text\"] = test_data['text'].apply(lambda x : remove_punctuation(x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d5767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dataset(pa.Table.from_pandas(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5607d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test(data):\n",
    "  return tokenizer(\n",
    "      data['text'],\n",
    "      truncation = True,\n",
    "      padding = 'max_length',\n",
    "      return_token_type_ids = True,\n",
    "      )\n",
    "\n",
    "encoded_test = test.map(transform_test, batched=True)\n",
    "encoded_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6323bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = trainer.predict(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = []\n",
    "\n",
    "for i in range(len(pred[0])):\n",
    "    pred_label.append((str)(np.argmax(pred[0][i])).zfill(2))\n",
    "    \n",
    "pred_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fceb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_data.assign(CLASS=pred_label)\n",
    "submission = submission.rename(columns={'CLASS':'class'})\n",
    "\n",
    "submission.drop(['text'], axis=1, inplace=True)\n",
    "submission = submission.transpose()\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# sub_dir = os.getenv('HOME')+'/aiffelthon/AIFFELTHON/TUNiB/submission'\n",
    "# submission_file_path = f'{sub_dir}/submission_klue-bert-base-en_fr_ch_8000.json'\n",
    "# result = submission.to_json(submission_file_path)\n",
    "\n",
    "# with open(submission_file_path) as f:\n",
    "#     parsed = json.load(f)\n",
    "\n",
    "# with open(submission_file_path, 'w') as f:\n",
    "#     json.dump(parsed, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
