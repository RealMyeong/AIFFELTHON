{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40de5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "96d649a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label_sentence</th>\n",
       "      <th>sentence</th>\n",
       "      <th>binary_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>1:길동 씨 이번에 이것 좀 처리해요\\n2:이거 제가 한 게 아닌데요\\n1:팀에서 ...</td>\n",
       "      <td>길동 씨 이번에 이것 좀 처리해요\\n이거 제가 한 게 아닌데요\\n팀에서 내가 네가 ...</td>\n",
       "      <td>공격 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>1:야 너 앞니 왜 그렇게 튀어나왔냐\\n2:태어날 때부터 그랬어 물어보지 마\\n1:...</td>\n",
       "      <td>야 너 앞니 왜 그렇게 튀어나왔냐\\n태어날 때부터 그랬어 물어보지 마\\n아 그럼 태...</td>\n",
       "      <td>공격 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1:원후야 학원 교재 사야 되는데 8만 원만 주면 안 돼\\n2:미안 나 오늘은 진짜...</td>\n",
       "      <td>원후야 학원 교재 사야 되는데 8만 원만 주면 안 돼\\n미안 나 오늘은 진짜 돈이 ...</td>\n",
       "      <td>공격 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1:너 저번에 술 먹은 날 기억해\\n2:아니 왜\\n1:야 300만 원만 가져와\\n2...</td>\n",
       "      <td>너 저번에 술 먹은 날 기억해\\n아니 왜\\n야 300만 원만 가져와\\n뭔 소리야  ...</td>\n",
       "      <td>공격 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>1:너 또 내말 무시하냐\\n1:이 새끼 널 좆으로 보나 본데\\n2:아냐 진짜 시간이...</td>\n",
       "      <td>너 또 내말 무시하냐\\n이 새끼 널 좆으로 보나 본데\\n아냐 진짜 시간이 없었어 미...</td>\n",
       "      <td>공격 대화</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class                                     label_sentence  \\\n",
       "0  직장 내 괴롭힘 대화  1:길동 씨 이번에 이것 좀 처리해요\\n2:이거 제가 한 게 아닌데요\\n1:팀에서 ...   \n",
       "1    기타 괴롭힘 대화  1:야 너 앞니 왜 그렇게 튀어나왔냐\\n2:태어날 때부터 그랬어 물어보지 마\\n1:...   \n",
       "2        갈취 대화  1:원후야 학원 교재 사야 되는데 8만 원만 주면 안 돼\\n2:미안 나 오늘은 진짜...   \n",
       "3        갈취 대화  1:너 저번에 술 먹은 날 기억해\\n2:아니 왜\\n1:야 300만 원만 가져와\\n2...   \n",
       "4        협박 대화  1:너 또 내말 무시하냐\\n1:이 새끼 널 좆으로 보나 본데\\n2:아냐 진짜 시간이...   \n",
       "\n",
       "                                            sentence binary_class  \n",
       "0  길동 씨 이번에 이것 좀 처리해요\\n이거 제가 한 게 아닌데요\\n팀에서 내가 네가 ...        공격 대화  \n",
       "1  야 너 앞니 왜 그렇게 튀어나왔냐\\n태어날 때부터 그랬어 물어보지 마\\n아 그럼 태...        공격 대화  \n",
       "2  원후야 학원 교재 사야 되는데 8만 원만 주면 안 돼\\n미안 나 오늘은 진짜 돈이 ...        공격 대화  \n",
       "3  너 저번에 술 먹은 날 기억해\\n아니 왜\\n야 300만 원만 가져와\\n뭔 소리야  ...        공격 대화  \n",
       "4  너 또 내말 무시하냐\\n이 새끼 널 좆으로 보나 본데\\n아냐 진짜 시간이 없었어 미...        공격 대화  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/aiffel/aiffel/aiffelthon/train_normalization.csv')\n",
    "data.rename(columns={'non_label_sentence':'sentence'}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0a6b4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_combi(origin, aug1, aug2, aug3, normal, nor_num):\n",
    "    \"\"\"\n",
    "    input : dataframe * 4, normal_conversation_num\n",
    "    output : concated_dataframe\n",
    "    \"\"\"\n",
    "    choice_num = int(len(origin)*0.33)\n",
    "    nor_num = nor_num\n",
    "    \n",
    "    ori = origin.copy()\n",
    "    aug1 = aug1.copy()\n",
    "    aug2 = aug2.copy()\n",
    "    aug3 = aug3.copy()\n",
    "    nor = normal.copy()\n",
    "    \n",
    "    from random import sample\n",
    "    sampled_aug1, sampled_aug2, sampled_aug3, sampled_nor = \\\n",
    "    aug1.sample(choice_num), aug2.sample(choice_num), aug3.sample(choice_num), nor.sample(nor_num)\n",
    "    \n",
    "    total = pd.concat([ori, sampled_aug1, sampled_aug2, sampled_aug3, sampled_nor], axis=0)\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aa1767bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input(Input):\n",
    "    \"\"\"\n",
    "    input : dataframe\n",
    "    output : train_x, train_y\n",
    "    \"\"\"\n",
    "    data = Input\n",
    "    sentences = data['sentence']\n",
    "    sentences = [sen for sen in sentences]\n",
    "\n",
    "    from soynlp.tokenizer import LTokenizer\n",
    "    vocab_size = 30000\n",
    "    \n",
    "    from soynlp.word import WordExtractor\n",
    "    word_extractor = WordExtractor(\n",
    "        min_frequency=100, \n",
    "        min_cohesion_forward=0.05,\n",
    "        min_right_branching_entropy=0.0\n",
    "    )\n",
    "\n",
    "    word_extractor.train(sentences)\n",
    "    words = word_extractor.extract()\n",
    "\n",
    "    cohesion_score = {word:score.cohesion_forward for word, score in words.items()}\n",
    "    tokenizer = LTokenizer(scores=cohesion_score)\n",
    "    \n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    tokenizer_tf = Tokenizer(num_words=vocab_size)\n",
    "    \n",
    "    tokenizer_tf.fit_on_texts(sentences)\n",
    "    sequences = tokenizer_tf.texts_to_sequences(sentences)\n",
    "    \n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    train_data = pad_sequences(sequences)\n",
    "    \n",
    "    train_label = data['class']\n",
    "    labels = {'협박 대화': 0, '갈취 대화': 1, '직장 내 괴롭힘 대화': 2, '기타 괴롭힘 대화': 3, '일반 대화': 4}\n",
    "    train_label = train_label.apply(lambda x: labels[x])\n",
    "    train_label = pd.get_dummies(train_label)\n",
    "    \n",
    "    print('train_x_shape :',train_data.shape)\n",
    "    print('train_y_length :',len(train_label))\n",
    "    \n",
    "    return train_data, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e5d53679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.563 Gbry 0.549 Gb\n",
      "all cohesion probabilities was computed. # words = 1511\n",
      "all branching entropies was computed # words = 71544\n",
      "all accessor variety was computed # words = 71544\n",
      "train_x_shape : (8701, 177)\n",
      "train_y_length : 8701\n"
     ]
    }
   ],
   "source": [
    "total = random_combi(data, data, data, data, data, 1000)\n",
    "x, y = generate_input(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2be011ae",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.588 Gbry 0.569 Gb\n",
      "all cohesion probabilities was computed. # words = 1515\n",
      "all branching entropies was computed # words = 70478\n",
      "all accessor variety was computed # words = 70478\n",
      "train_x_shape : (8701, 177)\n",
      "train_y_length : 8701\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0   370    60   203\n",
      "   448     6 15675    34    29    28    26  1002  2717     4    18   130\n",
      "   518    83   110    29  1054    26   289   114 15676   192     1    15\n",
      "   110    29  9838   771  3771   114  4905  1439   370    60   593  1305\n",
      "     1     4   370    60 15677  1501     1    29 11710]\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "3193    0\n",
      "917     1\n",
      "2669    1\n",
      "2241    0\n",
      "1855    0\n",
      "Name: 0, Length: 8701, dtype: uint8\n",
      "training was done. used memory 0.564 Gbry 0.559 Gb\n",
      "all cohesion probabilities was computed. # words = 1503\n",
      "all branching entropies was computed # words = 70782\n",
      "all accessor variety was computed # words = 70782\n",
      "train_x_shape : (8701, 177)\n",
      "train_y_length : 8701\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0  396   63  211  461    6 9695   34   30   28   27 1039\n",
      " 3962    4   19  138  575   85  122   30 1071   27  297  118 9696  191\n",
      "    2   15  122   30 7169  713 3764  118 5761 1372  396   63  581 1318\n",
      "    2    4  396   63 9697 1345    2   30 6382]\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "3753    0\n",
      "1198    0\n",
      "3257    1\n",
      "403     0\n",
      "476     0\n",
      "Name: 0, Length: 8701, dtype: uint8\n",
      "training was done. used memory 0.589 Gbry 0.574 Gb\n",
      "all cohesion probabilities was computed. # words = 1518\n",
      "all branching entropies was computed # words = 71845\n",
      "all accessor variety was computed # words = 71845\n",
      "train_x_shape : (8701, 174)\n",
      "train_y_length : 8701\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  317   62  184  449    6 8175   33   29   28   27 1138 3106    4   17\n",
      "  127  501   79  134   29 1019   27  273  110 8176  183    1   14  134\n",
      "   29 7202  768 2844  110 4893 1369  317   62  562 1163    1    4  317\n",
      "   62 8177 1448    1   29 6382]\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "2869    1\n",
      "799     0\n",
      "2280    0\n",
      "1117    0\n",
      "1541    0\n",
      "Name: 0, Length: 8701, dtype: uint8\n",
      "training was done. used memory 0.564 Gbry 0.559 Gb\n",
      "all cohesion probabilities was computed. # words = 1507\n",
      "all branching entropies was computed # words = 70952\n",
      "all accessor variety was computed # words = 70952\n",
      "train_x_shape : (8701, 177)\n",
      "train_y_length : 8701\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0   392    63   188\n",
      "   447     6 15604    32    29    28    27  1113  3773     4    18   135\n",
      "   548    81   122    29  1268    27   292   114 15605   202     1    15\n",
      "   122    29 11644   718  2977   114  4867  1413   392    63   556  1289\n",
      "     1     4   392    63 15606  1310     1    29  8219]\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "3465    0\n",
      "332     0\n",
      "2003    1\n",
      "1343    0\n",
      "3823    0\n",
      "Name: 0, Length: 8701, dtype: uint8\n",
      "training was done. used memory 0.589 Gbry 0.574 Gb\n",
      "all cohesion probabilities was computed. # words = 1526\n",
      "all branching entropies was computed # words = 71108\n",
      "all accessor variety was computed # words = 71108\n",
      "train_x_shape : (8701, 173)\n",
      "train_y_length : 8701\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0   454    62   194   469     6 15620    33\n",
      "    29    28    27  1023  3566     4    19   136   525    83   113    29\n",
      "  1331    27   311   120 15621   196     1    14   113    29  7263   749\n",
      "  3567   120  4869  1474   454    62   626  1332     1     4   454    62\n",
      " 15622  1579     1    29  9813]\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "2929    1\n",
      "2935    1\n",
      "362     0\n",
      "2501    0\n",
      "234     1\n",
      "Name: 0, Length: 8701, dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    total = random_combi(data, data, data, data, data, 1000)\n",
    "    x, y = generate_input(total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
