{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUJdwb8YGCG3",
    "outputId": "dff4ebc5-70e2-4d3d-b43a-6f18745c0ce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soynlp in /opt/conda/lib/python3.9/site-packages (0.0.493)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.9/site-packages (from soynlp) (1.0)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /opt/conda/lib/python3.9/site-packages (from soynlp) (1.21.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from soynlp) (1.7.1)\n",
      "Requirement already satisfied: psutil>=5.0.1 in /opt/conda/lib/python3.9/site-packages (from soynlp) (5.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.20.0->soynlp) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.20.0->soynlp) (3.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ppAVcCev7Td6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from konlpy.tag import Okt, Mecab\n",
    "from soynlp.word import WordExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8cyv2XpOllF"
   },
   "source": [
    "# 데이터\n",
    "- 전처리 및 맞춤법 검사가 된 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "CJ3lGtgaCMCz",
    "outputId": "3659dc8b-dc24-4f8e-8f4f-d7035fc5833a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_label_sentence</th>\n",
       "      <th>label_sentence</th>\n",
       "      <th>class</th>\n",
       "      <th>binary_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>역시 일기예보는 맞은 적이 한 번도 없어\\n요즘 잘 맞는 거 같던데\\n어제 오늘 비...</td>\n",
       "      <td>1:역시 일기예보는 맞은 적이 한 번도 없어\\n2:요즘 잘 맞는 거 같던데\\n1:어...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>일반 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>요즘엔 군대도 많이 편해 졌다고 하더라\\n맞아\\n다들 그 얘기 많이 하더라\\n모든 ...</td>\n",
       "      <td>1:요즘엔 군대도 많이 편해 졌다고 하더라\\n2:맞아\\n2:다들 그 얘기 많이 하더...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>일반 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>나 피아노 학원이나 다닐까\\n갑자기 뭔 놈에 피아노 학원\\n안 친 세월이 몇 년이야...</td>\n",
       "      <td>1:나 피아노 학원이나 다닐까\\n2:갑자기 뭔 놈에 피아노 학원\\n1:안 친 세월이...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>일반 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>우리 강아지가 자꾸 아무데나 똥을 싸\\n교육을 시켜야겠다\\n배변 훈련은 어디서 시켜...</td>\n",
       "      <td>1:우리 강아지가 자꾸 아무데나 똥을 싸\\n2:교육을 시켜야겠다\\n1:배변 훈련은 ...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>일반 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>언니  혼내는 거 아녀요\\n원래 혼내면서 배우는 거지\\n난 솔직히 아소비 보내고 싶...</td>\n",
       "      <td>1:언니 혼내는 거 아녀요\\n2:원래 혼내면서 배우는 거지\\n1:난 솔직히 아소비 ...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>일반 대화</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  non_label_sentence  \\\n",
       "0  역시 일기예보는 맞은 적이 한 번도 없어\\n요즘 잘 맞는 거 같던데\\n어제 오늘 비...   \n",
       "1  요즘엔 군대도 많이 편해 졌다고 하더라\\n맞아\\n다들 그 얘기 많이 하더라\\n모든 ...   \n",
       "2  나 피아노 학원이나 다닐까\\n갑자기 뭔 놈에 피아노 학원\\n안 친 세월이 몇 년이야...   \n",
       "3  우리 강아지가 자꾸 아무데나 똥을 싸\\n교육을 시켜야겠다\\n배변 훈련은 어디서 시켜...   \n",
       "4  언니  혼내는 거 아녀요\\n원래 혼내면서 배우는 거지\\n난 솔직히 아소비 보내고 싶...   \n",
       "\n",
       "                                      label_sentence  class binary_class  \n",
       "0  1:역시 일기예보는 맞은 적이 한 번도 없어\\n2:요즘 잘 맞는 거 같던데\\n1:어...  일반 대화        일반 대화  \n",
       "1  1:요즘엔 군대도 많이 편해 졌다고 하더라\\n2:맞아\\n2:다들 그 얘기 많이 하더...  일반 대화        일반 대화  \n",
       "2  1:나 피아노 학원이나 다닐까\\n2:갑자기 뭔 놈에 피아노 학원\\n1:안 친 세월이...  일반 대화        일반 대화  \n",
       "3  1:우리 강아지가 자꾸 아무데나 똥을 싸\\n2:교육을 시켜야겠다\\n1:배변 훈련은 ...  일반 대화        일반 대화  \n",
       "4  1:언니 혼내는 거 아녀요\\n2:원래 혼내면서 배우는 거지\\n1:난 솔직히 아소비 ...  일반 대화        일반 대화  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/aiffel/train_1000_mk2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.489 Gbry 0.412 Gb\n",
      "all cohesion probabilities was computed. # words = 868\n",
      "all branching entropies was computed # words = 23278\n",
      "all accessor variety was computed # words = 23278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4870, 191)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = data.non_label_sentence\n",
    "sentences = [sen for sen in sentences]\n",
    "\n",
    "from soynlp.tokenizer import LTokenizer\n",
    "vocab_size = 30000\n",
    "\n",
    "word_extractor = WordExtractor(\n",
    "    min_frequency=100, # example\n",
    "    min_cohesion_forward=0.05,\n",
    "    min_right_branching_entropy=0.0\n",
    ")\n",
    "\n",
    "word_extractor.train(sentences)\n",
    "words = word_extractor.extract()\n",
    "\n",
    "cohesion_score = {word:score.cohesion_forward for word, score in words.items()}\n",
    "tokenizer = LTokenizer(scores=cohesion_score)\n",
    "\n",
    "sentences = [tokenizer.tokenize(sen) for sen in sentences]\n",
    "tokenizer_tf = Tokenizer(num_words=vocab_size)\n",
    "tokenizer_tf.fit_on_texts(sentences)\n",
    "word_dic = tokenizer_tf.word_index\n",
    "sequences = tokenizer_tf.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences)\n",
    "np.shape(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48800"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecw2j-NTIvvu",
    "outputId": "6dd99533-cdd5-450b-fa09-be78c32752e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4870 4870\n"
     ]
    }
   ],
   "source": [
    "train_data = padded\n",
    "train_label = data['class']\n",
    "print(len(train_data), len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'협박 대화': 0, '갈취 대화': 1, '직장 내 괴롭힘 대화': 2, '기타 괴롭힘 대화': 3, '일반 대화': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qt0u-2UTKUsF",
    "outputId": "3789632e-f39d-4718-e403-a144f0db6713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3896 487 487\n",
      "3896 487 487\n"
     ]
    }
   ],
   "source": [
    "labels = {'협박 대화': 0, '갈취 대화': 1, '직장 내 괴롭힘 대화': 2, '기타 괴롭힘 대화': 3, '일반 대화': 4}\n",
    "train_label = train_label.apply(lambda x: labels[x])\n",
    "train_label = pd.get_dummies(train_label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train_data, train_label, test_size=0.2, random_state=22)\n",
    "valid_X, test_X, valid_Y, test_Y = train_test_split(test_X, test_Y, test_size=0.5, random_state=22)\n",
    "\n",
    "print(len(train_X), len(valid_X), len(test_X))\n",
    "print(len(train_Y), len(valid_Y), len(test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzB2haBJLJoH"
   },
   "source": [
    "# 모델 \n",
    "- LSTM 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8kkPNDrLKZ7",
    "outputId": "8457f8f7-ebd4-4ea3-b938-93b4c4e8b1e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 1024)        30720000  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 128)         590336    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 128)         131584    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30000)             1950000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 150005    \n",
      "=================================================================\n",
      "Total params: 33,591,333\n",
      "Trainable params: 33,591,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word_vector_dim = 1024\n",
    "labels_size = len(labels)\n",
    "hidden_size = 128\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(hidden_size, return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(hidden_size, return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(hidden_size//2))\n",
    "model.add(tf.keras.layers.Dense(vocab_size, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "model.add(tf.keras.layers.Dense(labels_size, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "a0sS-wccLaok",
    "outputId": "78166618-b960-4af9-b3da-dabbb73cdf2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 8s 169ms/step - loss: 1.3803 - accuracy: 0.3568 - val_loss: 0.9637 - val_accuracy: 0.5708\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 0.7025 - accuracy: 0.7017 - val_loss: 0.7316 - val_accuracy: 0.7269\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 0.2734 - accuracy: 0.9032 - val_loss: 0.7401 - val_accuracy: 0.7474\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 2s 110ms/step - loss: 0.1034 - accuracy: 0.9666 - val_loss: 1.0191 - val_accuracy: 0.7515\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 0.0367 - accuracy: 0.9877 - val_loss: 1.1399 - val_accuracy: 0.7536\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: 1.0513 - val_accuracy: 0.7803\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 1.5171 - val_accuracy: 0.7598\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 1.3403 - val_accuracy: 0.7721\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 1.3505 - val_accuracy: 0.7556\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 0.0028 - accuracy: 0.9985 - val_loss: 1.4199 - val_accuracy: 0.7700\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=10\n",
    "\n",
    "history = model.fit(train_X,\n",
    "                    train_Y,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(valid_X, valid_Y),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_000</th>\n",
       "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_001</th>\n",
       "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_002</th>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_003</th>\n",
       "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_004</th>\n",
       "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_495</th>\n",
       "      <td>미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_496</th>\n",
       "      <td>교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_497</th>\n",
       "      <td>야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_498</th>\n",
       "      <td>야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_499</th>\n",
       "      <td>엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...\n",
       "t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...\n",
       "t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...\n",
       "t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...\n",
       "t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...\n",
       "...                                                  ...\n",
       "t_495  미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...\n",
       "t_496  교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...\n",
       "t_497  야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...\n",
       "t_498  야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...\n",
       "t_499  엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = '/aiffel/test.json'\n",
    "with open(test_file_path, mode='rt', encoding='utf-8') as f:\n",
    "    test_dataset = pd.read_json(f)\n",
    "    \n",
    "test_data = test_dataset.transpose()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sen for sen in test_data['text']]\n",
    "sentences = [tokenizer.tokenize(sen) for sen in sentences]\n",
    "sequences = tokenizer_tf.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 172)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '2', '2', '4', '1', '0', '0', '1', '4', '1']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(padded)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred_label = []\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_label.append((str)(np.argmax(pred[i])))\n",
    "    \n",
    "pred_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '02', '02', '04', '01', '00', '00', '01', '04', '01']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_change = {'0':'00', '1':'01', '2':'02', '3':'03', '4':'04'}\n",
    "\n",
    "sub_label = []\n",
    "\n",
    "for pre in pred_label:\n",
    "    sub_label.append(label_change[pre])\n",
    "\n",
    "sub_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_data.assign(CLASS=sub_label)\n",
    "submission = submission.rename(columns={'CLASS':'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_000</th>\n",
       "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_001</th>\n",
       "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_002</th>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_003</th>\n",
       "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_004</th>\n",
       "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text class\n",
       "t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...    00\n",
       "t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...    02\n",
       "t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...    02\n",
       "t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...    04\n",
       "t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...    01"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'그 사람 누구냐?  누구말하는거야?  다 알면서 모른척 하지마. 둘다 쏴버리기 전에.  아니 정말 왜이래? 누굴말하는거냐고.  어제 밤에 전화온 그새끼 말이야. 번호 알아놨으니까 죽이기 전에 다 불어라.  아! 김대리? 그냥 회사사람이야. 오해하지마  회사사람이란 인간이 그 오밤중에 사랑한다고 보고싶다고 하냐? 진짜 다 죽여버리기 전에 솔직히 말해라.  정말 아니야. 왜 이래? 오해라니까.  안되겠다. 그럼 지난주 점심시간에 모텔은 왜갔냐?  어??? 그냥 피곤해서 쉬러간거야. 오해야.  안되겠다. 그냥 불지르고 다 끝내자.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['text'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'협박 대화': 0, '갈취 대화': 1, '직장 내 괴롭힘 대화': 2, '기타 괴롭힘 대화': 3, '일반 대화': 4}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_000</th>\n",
       "      <th>t_001</th>\n",
       "      <th>t_002</th>\n",
       "      <th>t_003</th>\n",
       "      <th>t_004</th>\n",
       "      <th>t_005</th>\n",
       "      <th>t_006</th>\n",
       "      <th>t_007</th>\n",
       "      <th>t_008</th>\n",
       "      <th>t_009</th>\n",
       "      <th>...</th>\n",
       "      <th>t_490</th>\n",
       "      <th>t_491</th>\n",
       "      <th>t_492</th>\n",
       "      <th>t_493</th>\n",
       "      <th>t_494</th>\n",
       "      <th>t_495</th>\n",
       "      <th>t_496</th>\n",
       "      <th>t_497</th>\n",
       "      <th>t_498</th>\n",
       "      <th>t_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>00</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>04</td>\n",
       "      <td>01</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>00</td>\n",
       "      <td>04</td>\n",
       "      <td>00</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      t_000 t_001 t_002 t_003 t_004 t_005 t_006 t_007 t_008 t_009  ... t_490  \\\n",
       "class    00    02    02    04    01    00    00    01    04    01  ...    00   \n",
       "\n",
       "      t_491 t_492 t_493 t_494 t_495 t_496 t_497 t_498 t_499  \n",
       "class    04    00    01    01    02    02    01    02    00  \n",
       "\n",
       "[1 rows x 500 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.drop(['text'], axis=1, inplace=True)\n",
    "submission = submission.transpose()\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "submission_file_path = '/aiffel/submission_LSTM_1000_수정'\n",
    "result = submission.to_json(submission_file_path)\n",
    "\n",
    "with open(submission_file_path) as f:\n",
    "    parsed = json.load(f)\n",
    "\n",
    "with open(submission_file_path, 'w') as f:\n",
    "    json.dump(parsed, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
